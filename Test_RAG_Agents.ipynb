{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGSMITH_API_KEY=os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT=os.getenv(\"LANGSMITH_PROJECT\")\n",
    "os.environ[\"LANGSMITH_TRACING\"]=\"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain-agent'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGSMITH_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\dev25\\Building-Agentic-AI\\Langgraph_Agent\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm1 = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")'''\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "llm2=ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Divakar Kumar, it's nice to meet you! ðŸ‘‹ \n",
      "\n",
      "What can I do for you today? ðŸ˜Š  \n",
      "\n",
      "\n",
      "ISRO, the Indian Space Research Organisation, has conducted incredibly successful moon missions, particularly Chandrayaan-1, Chandrayaan-2, and Chandrayaan-3.  Here's a breakdown of how they've accomplished these feats:\n",
      "\n",
      "**Key Steps in an ISRO Moon Mission:**\n",
      "\n",
      "1. **Planning and Design:** This involves:\n",
      "    * **Defining mission objectives:** What scientific data do they want to gather?\n",
      "    * **Selecting the spacecraft:** Determining the necessary instruments, power systems, and other components.\n",
      "    * **Developing launch strategy:** Choosing the appropriate launch vehicle and trajectory.\n",
      "2. **Building the Spacecraft:**\n",
      "    * **Manufacturing:** ISRO has its own manufacturing facilities and collaborates with other Indian companies.\n",
      "    * **Testing:** Rigorous testing is conducted in different environments to ensure spacecraft reliability.\n",
      "3. **Launch:**\n",
      "    * ISRO uses its powerful launch vehicles, such as the GSLV Mk III, to send the spacecraft into orbit.\n",
      "4. **Lunar Trajectory:**\n",
      "    * The spacecraft takes a carefully calculated path to the Moon, using gravity assists and maneuvers.\n",
      "5. **Lunar Orbit Insertion:**\n",
      "    * The spacecraft enters lunar orbit, slowing down using its engines.\n",
      "6. **Scientific Operations:**\n",
      "    * Once in orbit or on the surface, the spacecraft deploys its instruments to collect data about the Moon. This data is transmitted back to Earth.\n",
      "\n",
      "**Chandrayaan Missions:**\n",
      "\n",
      "* **Chandrayaan-1 (2008):** This mission successfully orbited the Moon and discovered water molecules in lunar soil, a groundbreaking discovery.\n",
      "* **Chandrayaan-2 (2019):** This mission aimed to land a rover on the Moon, but the lander unfortunately crashed. However, the orbiter continues to provide valuable data.\n",
      "* **Chandrayaan-3 (2023):** This mission successfully landed a rover on the Moon, making India the fourth country to achieve a soft landing.\n",
      "\n",
      "**ISRO's Success Factors:**\n",
      "\n",
      "* **Technical Expertise:** ISRO has a highly skilled workforce of scientists, engineers, and technicians.\n",
      "* **Self-Reliance:** ISRO has developed its own launch vehicles and spacecraft, reducing dependence on foreign technology.\n",
      "* **Cost-Effectiveness:** ISRO is known for its ability to achieve ambitious missions with limited budgets.\n",
      "* **Visionary Leadership:** ISRO has had strong leadership that has driven its ambitious space exploration program.\n",
      "\n",
      "**Looking Ahead:**\n",
      "\n",
      "ISRO continues to plan and execute ambitious missions, including:\n",
      "\n",
      "* **Gaganyaan:** India's first human spaceflight program.\n",
      "* **Lunar Polar Exploration Mission:** A future mission to further explore the lunar poles.\n",
      "* **Venus Orbiter Mission:** To study the atmosphere and surface of Venus.\n",
      "\n",
      "\n",
      "\n",
      "ISRO's success in reaching the Moon is a testament to India's growing technological prowess and its commitment to scientific exploration.\n",
      "\n",
      "goodbye take care yourself\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question=input(\"type your question. if you want to quit the chat write quit\")\n",
    "    if question !=\"quit\":\n",
    "        print(llm2.invoke(question).content)\n",
    "    else:\n",
    "        print(\"goodbye take care yourself\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory=RunnableWithMessageHistory(llm2,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Divakar Kumar, it's nice to meet you! ðŸ‘‹\\n\\nHow can I help you today? ðŸ˜Š  \\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"Hi! I'm Divakar Kumar\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Divakar Kumar.  ðŸ˜„ \\n\\nI remember that from when you introduced yourself! \\n\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"tell me what is my name?\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Divakar Kumar\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Divakar Kumar, it's nice to meet you! ðŸ‘‹\\n\\nHow can I help you today? ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 17, 'total_tokens': 45, 'completion_time': 0.050909091, 'prompt_time': 0.001929826, 'queue_time': 0.015154643000000002, 'total_time': 0.052838917}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a768b90c-d3c4-46d6-93a1-ba18de83465b-0', usage_metadata={'input_tokens': 17, 'output_tokens': 28, 'total_tokens': 45}), HumanMessage(content='tell me what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Divakar Kumar.  ðŸ˜„ \\n\\nI remember that from when you introduced yourself! \\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 59, 'total_tokens': 83, 'completion_time': 0.045972989, 'prompt_time': 0.005244288, 'queue_time': 0.01851708, 'total_time': 0.051217277}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-239aa8e9-57ae-4464-880e-fc4ad4a4f363-0', usage_metadata={'input_tokens': 59, 'output_tokens': 24, 'total_tokens': 83})])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough , RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\divak\\AppData\\Local\\Programs\\Python\\Python311\\ipykernel_6520\\905206988.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  loader = DirectoryLoader('F:\\dev25\\Building-Agentic-AI\\Langgraph_Agent\\data', glob=\"./*.txt\", loader_cls=TextLoader)\n"
     ]
    }
   ],
   "source": [
    "### Reading the txt files from source directory\n",
    "\n",
    "loader = DirectoryLoader('F:\\dev25\\Building-Agentic-AI\\Langgraph_Agent\\data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "'''from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "'''\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm2\n",
    "    | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text states Gross Bookings grew 19% year-over-year and 26%, but it doesn't specify the timeframe for the 26% growth or the specific year this growth occurred.  Therefore, it's impossible to determine how much Gross Bookings grew *specifically* in 2022 based on the given context.\n"
     ]
    }
   ],
   "source": [
    "question =\"How much Gross Bookings grew in 2022?\"\n",
    "print(retrieval_chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
