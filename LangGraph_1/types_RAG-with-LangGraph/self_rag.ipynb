{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ccf4e50",
   "metadata": {},
   "source": [
    "### **Self RAG**\n",
    "Large language models possess transformative capabilities across various tasks but often produce responses with factual inaccuracies due to their reliance on parametric knowledge. Retrieval-Augmented Generation was introduced to address this by incorporating relevant external knowledge. However, conventional RAG methods retrieve a fixed number of passages without adaptability, leading to irrelevant or inconsistent outputs. To overcome these limitations, Self-Reflective Retrieval-Augmented Generation (Self-RAG) was developed. Self-RAG enhances LLM quality and factuality through adaptive retrieval and self-reflection using reflection tokens, allowing models to tailor their behavior to diverse tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5766943b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b29db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGSMITH_API_KEY=os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_TRACING\"]=\"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a6edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dcfee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c0ccf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d0e9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ceb1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032483f2",
   "metadata": {},
   "source": [
    "Let's look into the retriever grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ca76e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\dev25\\Building-Agentic-AI\\Langgraph_Agent\\LangGraph_1\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4657ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069e9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader checking if a document is relevant to a user’s question.The check has to be done very strictly..  \n",
    "If the document has words or meanings related to the question, mark it as relevant.  \n",
    "Give a simple 'yes' or 'no' answer to show if the document is relevant or not.\"\"\"\n",
    "    \n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b692aff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a grader checking if a document is relevant to a user’s question.The check has to be done very strictly..  \\nIf the document has words or meanings related to the question, mark it as relevant.  \\nGive a simple 'yes' or 'no' answer to show if the document is relevant or not.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, template='Retrieved document: \\n\\n {document} \\n\\n User question: {question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbaa6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"what is ai agent?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c75ee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divak\\AppData\\Local\\Programs\\Python\\Python311\\ipykernel_6812\\10663643.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b05c7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Generative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Boiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a98632",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt = docs[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7d6c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb4a51e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "print(my_retrieval_grader.invoke({\"document\":doc_txt,\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a78292a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"who is sunny Divakar?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5db9cdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "print(my_retrieval_grader.invoke({\"document\":doc_txt,\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb2ea9",
   "metadata": {},
   "source": [
    "let's look into the data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0695b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fb2570c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fb8dcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Generative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Boiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e949c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a356d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"what is a AI agent?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b554b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0acbc17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='An AI agent is a program, often powered by a large language model (LLM), that can perform tasks autonomously.  \\n\\nIt uses planning, memory, and tool use capabilities to achieve goals and interact with its environment. \\nExamples of AI agents include AutoGPT and BabyAGI. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 2121, 'total_tokens': 2184, 'completion_time': 0.114545455, 'prompt_time': 0.072839357, 'queue_time': 0.23489695, 'total_time': 0.187384812}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4318d4cd-c549-4e3b-964e-f12b32c1f9c5-0', usage_metadata={'input_tokens': 2121, 'output_tokens': 63, 'total_tokens': 2184})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd44eeae",
   "metadata": {},
   "source": [
    "Hallucination Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a52d377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11e91b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c889a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader evaluating whether a language model's generation is grounded in or supported by a set of retrieved facts.  \n",
    "Respond with a simple 'yes' or 'no'. 'Yes' means the generation is grounded in or supported by the retrieved facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb0c2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucinations_grader = hallucination_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84df133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "print(hallucinations_grader.invoke({\"documents\": docs, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c8178",
   "metadata": {},
   "source": [
    "Answer Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ab4af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Answer Grader\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "print(answer_grader.invoke({\"question\": question, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9137a",
   "metadata": {},
   "source": [
    "Question Re-writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "beeb9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a question re-writer that converts an input question into a better optimized version for vector store retrieval document.  \n",
    "You are given both a question and a document.  \n",
    "- First, check if the question is relevant to the document by identifying a connection or relevance between them.  \n",
    "- If there is a little relevancy, rewrite the question based on the semantic intent of the question and the context of the document.  \n",
    "- If no relevance is found, simply return this single word \"question not relevant.\" dont return the entire phrase \n",
    "Your goal is to ensure the rewritten question aligns well with the document for better retrieval.\"\"\"\n",
    "     \n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\"\"\"Here is the initial question: \\n\\n {question} \\n,\n",
    "             Here is the document: \\n\\n {documents} \\n ,\n",
    "             Formulate an improved question. if possible other return 'question not relevant'.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b1c5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"who is a current indian prime minister?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6920de4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question not relevant \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_rewriter.invoke({\"question\":question,\"documents\":docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe805c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    filter_documents: List[str]\n",
    "    unfilter_documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b603c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:AgentState):\n",
    "    print(\"----RETRIEVE----\")\n",
    "    question=state['question']\n",
    "    documents=retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef437dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state:AgentState):\n",
    "    print(\"----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\")\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    filtered_docs = []\n",
    "    unfiltered_docs = []\n",
    "    for doc in documents:\n",
    "        score=my_retrieval_grader.invoke({\"question\":question, \"document\":doc})\n",
    "        grade=score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"----GRADE: DOCUMENT RELEVANT----\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\"----GRADE: DOCUMENT NOT RELEVANT----\")\n",
    "            unfiltered_docs.append(doc)\n",
    "    if len(unfiltered_docs)>1:\n",
    "        return {\"unfilter_documents\": unfiltered_docs,\"filter_documents\":[], \"question\": question}\n",
    "    else:\n",
    "        return {\"filter_documents\": filtered_docs,\"unfilter_documents\":[],\"question\": question}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6366bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state:AgentState):\n",
    "    print(\"----ACCESS GRADED DOCUMENTS----\")\n",
    "    state[\"question\"]\n",
    "    unfiltered_documents = state[\"unfilter_documents\"]\n",
    "    filtered_documents = state[\"filter_documents\"]\n",
    "    \n",
    "    \n",
    "    if unfiltered_documents:\n",
    "        print(\"----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\")\n",
    "        return \"transform_query\"\n",
    "    if filtered_documents:\n",
    "        print(\"----DECISION: GENERATE----\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c74377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:AgentState):\n",
    "    print(\"----GENERATE----\")\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    generation = rag_chain.invoke({\"context\": documents,\"question\":question})\n",
    "    return {\"documents\":documents,\"question\":question,\"generation\":generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1079aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "def transform_query(state:AgentState):\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    print(f\"this is my document{documents}\")\n",
    "    response = question_rewriter.invoke({\"question\":question,\"documents\":documents})\n",
    "    print(f\"----RESPONSE---- {response}\")\n",
    "    if response == 'question not relevant':\n",
    "        print(\"----QUESTION IS NOT AT ALL RELEVANT----\")\n",
    "        return {\"documents\":documents,\"question\":response,\"generation\":\"question was not at all relevant\"}\n",
    "    else:   \n",
    "        return {\"documents\":documents,\"question\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "908fecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate_after_transformation(state:AgentState):\n",
    "    question=state[\"question\"]\n",
    "    \n",
    "    if question==\"question not relevant\":\n",
    "        return \"query_not_at_all_relevant\"\n",
    "    else:\n",
    "        return \"Retriever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58af7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "def grade_generation_vs_documents_and_question(state:AgentState):\n",
    "    print(\"---CHECK HELLUCINATIONS---\")\n",
    "    question= state['question']\n",
    "    documents = state['documents']\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    score = hallucinations_grader.invoke({\"documents\":documents,\"generation\":generation})\n",
    "    \n",
    "    grade = score.binary_score\n",
    "    \n",
    "    #Check hallucinations\n",
    "    if grade=='yes':\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        \n",
    "        print(\"---GRADE GENERATION vs QUESTION ---\")\n",
    "        \n",
    "        score = answer_grader.invoke({\"question\":question,\"generation\":generation})\n",
    "        \n",
    "        grade = score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"---DECISION: GENERATION ADDRESS THE QUESTION ---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "        \"not useful\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ac918",
   "metadata": {},
   "source": [
    "From here the Langgraph workflow will start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41638fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x152f6792480>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Docs_Vector_Retrieve\", retrieve)\n",
    "workflow.add_node(\"Grading_Generated_Documents\", grade_documents) \n",
    "workflow.add_node(\"Content_Generator\", generate)\n",
    "workflow.add_node(\"Transform_User_Query\", transform_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5929158f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x152f6792480>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START,\"Docs_Vector_Retrieve\")\n",
    "workflow.add_edge(\"Docs_Vector_Retrieve\",\"Grading_Generated_Documents\")\n",
    "workflow.add_conditional_edges(\"Grading_Generated_Documents\",\n",
    "                            decide_to_generate,\n",
    "                            {\n",
    "                            \"generate\": \"Content_Generator\",\n",
    "                            \"transform_query\": \"Transform_User_Query\"\n",
    "                            }\n",
    "                            )\n",
    "workflow.add_conditional_edges(\"Content_Generator\",\n",
    "                            grade_generation_vs_documents_and_question,\n",
    "                            {\n",
    "                            \"useful\": END,\n",
    "                            \"not useful\": \"Transform_User_Query\",\n",
    "                            }\n",
    "                            )\n",
    "workflow.add_conditional_edges(\"Transform_User_Query\",\n",
    "                decide_to_generate_after_transformation,\n",
    "                {\n",
    "                \"Retriever\":\"Docs_Vector_Retrieve\",\n",
    "                \"query_not_at_all_relevant\":END\n",
    "                }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aee890ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display # type: ignore\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1fd84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"Explain how the different types of agent memory work?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c75e2b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The text describes two types of agent memory: short-term memory, which is used for in-context learning, and long-term memory, which stores information over extended periods using a vector store for fast retrieval. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 2126, 'total_tokens': 2173, 'completion_time': 0.085454545, 'prompt_time': 0.077520426, 'queue_time': 0.23821239400000002, 'total_time': 0.162974971}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f93e7bc-9386-479b-bc4c-96acb3a7f881-0', usage_metadata={'input_tokens': 2126, 'output_tokens': 47, 'total_tokens': 2173})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0592ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who is a prompt engineering?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75a0d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Prompt engineering is the practice of designing effective inputs, called prompts, for large language models (LLMs) to elicit desired responses. It involves techniques like zero-shot and few-shot prompting to guide the LLM's behavior without altering its core weights.  The goal is to improve the alignment and steerability of the LLM, enabling it to generate more accurate and relevant outputs. \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 1107, 'total_tokens': 1189, 'completion_time': 0.149090909, 'prompt_time': 0.038685924, 'queue_time': 0.24198783700000004, 'total_time': 0.187776833}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b584a1da-9f65-4675-9ffa-25bd65bc6bcc-0', usage_metadata={'input_tokens': 1107, 'output_tokens': 82, 'total_tokens': 1189})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "378e494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what is role of data structure while creating ai agentic pattern?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b95dea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what is role of c language and php while creating ai agentic pattern?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fa2f00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.')]\n",
      "----RESPONSE---- What role do external tools and APIs play in LLM-powered agent systems, particularly for tasks like code execution and accessing proprietary information?  \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What role do external tools and APIs play in LLM-powered agent systems, particularly for tasks like code execution and accessing proprietary information?  \\n',\n",
       " 'generation': AIMessage(content='External tools and APIs allow LLM-powered agents to access information and capabilities beyond their own training data, such as code execution and proprietary data sources.  The agents learn to use these tools by identifying when they are needed, selecting the appropriate API, and refining their input until they get satisfactory results.  This integration of external tools significantly expands the problem-solving abilities of LLM agents. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 2056, 'total_tokens': 2138, 'completion_time': 0.149090909, 'prompt_time': 0.070551475, 'queue_time': 0.234567624, 'total_time': 0.219642384}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b159222-31b9-45a7-93cb-32d15523a410-0', usage_metadata={'input_tokens': 2056, 'output_tokens': 82, 'total_tokens': 2138}),\n",
       " 'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Tool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Boiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Whether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:')],\n",
       " 'filter_documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Tool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Boiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#'),\n",
       "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Whether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:')],\n",
       " 'unfilter_documents': []}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86d1a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who is a first president of USA?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e80e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='},\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Tips for Example Selection#'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"')]\n",
      "----RESPONSE---- This question is not directly related to the provided documents. \n",
      "\n",
      "\n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Because these documents are long, each document is split into paragraphs of 6 sentences, $\\\\{p\\\\}$. Paragraphs are ranked by TF-IDF based cosine similarity between evidence paragraphs and the query. Only the most relevant paragraph is used in the prompt to produce an answer $a$.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='\\\\mid q, p_i)$, where $p_\\\\text{tf-idf} (p_i \\\\mid q)$ is the normalized cosine similarities between the TF-IDF passage and question representations.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Fig. 4. The format of API calls in TALM. (Image source: Parisi et al. 2022).'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",')]\n",
      "----RESPONSE---- question not relevant \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='One observation with SituatedQA dataset for questions grounded in different dates is that despite LM (pretraining cutoff is year 2020) has access to latest information via Google Search, its performance on post-2020 questions are still a lot worse than on pre-2020 questions. This suggests the existence of some discrepencies or conflicting parametric between contextual information and model internal knowledge.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='For closed-book QA, each demonstration is formatted as follows to construct few-shot prompts. Swapping the question with the evidence (longer distance between questions and answers) is found to consistently yield lower results across all datasets.\\nEvidence: ...\\nQuestion: ...\\nAnswer: ...\\nThe answer probability is computed in three ways:')]\n",
      "----RESPONSE---- How does prompt engineering impact the performance of language models on tasks with factual questions and evidence? \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Prompt engineering significantly impacts the performance of language models on factual question-answering tasks by guiding the model to focus on relevant information and structure responses logically.  \\n\\nThe effectiveness of different prompt engineering techniques can vary depending on the specific model and task, requiring experimentation to find optimal approaches.  \\n\\nFor tasks involving reasoning, adding explanations to prompts can have a small to moderate impact, but it's important to ensure the explanations are factual. \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 1121, 'total_tokens': 1212, 'completion_time': 0.165454545, 'prompt_time': 0.039433208, 'queue_time': 0.23760716599999998, 'total_time': 0.204887753}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e4c7dcc8-e679-4af9-a7ae-eca3b48cfeb6-0', usage_metadata={'input_tokens': 1121, 'output_tokens': 91, 'total_tokens': 1212})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2578e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
